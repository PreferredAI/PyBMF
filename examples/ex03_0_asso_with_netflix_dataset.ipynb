{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from datasets import Dataset, NetflixData, NetflixGenreData\n",
    "X_data = NetflixData(small=True)\n",
    "Z_data = NetflixGenreData(small=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (9980, 3362)\n",
      "filtered shape: (3690, 1069)\n",
      "[I] sampling with given indices\n",
      "filtered shape: (3690, 3362)\n",
      "[I] sampling with given indices\n",
      "filtered shape: (3690, 1069)\n",
      "[I] sampling with given indices\n",
      "filtered shape: (22, 1069)\n"
     ]
    }
   ],
   "source": [
    "# down-sampling by constraints\n",
    "\n",
    "sum_u, sum_v = X_data.X.sum\n",
    "\n",
    "# idx_u = sum_u > 130\n",
    "# idx_v = sum_v > 200\n",
    "\n",
    "idx_u = sum_u > 40\n",
    "idx_v = sum_v > 60\n",
    "\n",
    "print(\"original shape:\", X_data.X.shape)\n",
    "print(\"filtered shape:\", (sum(idx_u), sum(idx_v)))\n",
    "\n",
    "X_data.sample(idx=idx_u, axis=0)\n",
    "print(\"filtered shape:\", X_data.X.shape)\n",
    "X_data.sample(idx=idx_v, axis=1)\n",
    "print(\"filtered shape:\", X_data.X.shape)\n",
    "Z_data.sample(idx=idx_v, axis=1)\n",
    "print(\"filtered shape:\", Z_data.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] sampling to size 1000\n",
      "[I]   Data seed    : 1698201358\n",
      "(1000, 1069)\n",
      "[I] sampling to size 500\n",
      "(1000, 500)\n",
      "[I] sampling with given indices\n",
      "(22, 500)\n"
     ]
    }
   ],
   "source": [
    "# down-sampling by random\n",
    "\n",
    "X_data.sample(n=1000, axis=0)\n",
    "print(X_data.X.shape)\n",
    "idx_v = X_data.sample(n=500, axis=1)\n",
    "print(X_data.X.shape)\n",
    "Z_data.sample(idx=idx_v, axis=1)\n",
    "print(Z_data.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import Asso\n",
    "# import multiprocessing\n",
    "\n",
    "# def asso_fit(params):\n",
    "#     k, tau, w, train_set, val_set = params\n",
    "#     asso = Asso(k=k, tau=tau, w=w)\n",
    "#     asso.fit(train_set=train_set, display=True)\n",
    "#     tpr, fpr = asso.eval(test_set=val_set, triplet=True)\n",
    "\n",
    "#     with open('.\\output\\exp01.txt', \"w\") as f:\n",
    "#         line = f'k: {k}\\t tau: {tau}\\t w: {w}\\t tpr: {tpr}\\t fpr: {fpr}\\n'\n",
    "#         f.write(f'{line}\\n')\n",
    "\n",
    "# params = [[k], tau_list, w_list, [ds_train], [ds_val]]\n",
    "# params = list(itertools.product(*params))\n",
    "\n",
    "# pool = multiprocessing.Pool()\n",
    "\n",
    "# outputs_async = pool.map_async(asso_fit, params)\n",
    "# outputs = outputs_async.get()\n",
    "# print(\"Output: {}\".format(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] cross-validation, sampling positives\n",
      "[I]   Data seed    : 1997\n",
      "[I]   partition    : [0, 10729, 21458, 32187, 42916, 53645]\n",
      "[I]   test_size    : 0\n",
      "[I]   seed         : 1997\n",
      "[I] getting cross-validation indices\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 42916\n",
      "[I]   current val size     : 10729\n",
      "[I] cross-validation, sampling negatives\n",
      "[I]   Data seed    : 6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53645/53645 [00:48<00:00, 1104.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I]   n_negatives  : 53645\n",
      "[I]   test_size    : 0\n",
      "[I]   seed         : 6666\n",
      "[I] getting cross-validation indices\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 0\n",
      "[I]   current val size     : 53645\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object dtype is not supported by sparse matrices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Dropbox\\PyBMF\\ex04_asso_netflix.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X_data\u001b[39m.\u001b[39mcross_validation(test_size\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, n_folds\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, current_fold\u001b[39m=\u001b[39mfold, seed\u001b[39m=\u001b[39m\u001b[39m1997\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m pos_train_val_size \u001b[39m=\u001b[39m X_data\u001b[39m.\u001b[39mpos_train_size \u001b[39m+\u001b[39m X_data\u001b[39m.\u001b[39mpos_val_size\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m X_data\u001b[39m.\u001b[39;49mcv_negative_sample(n_folds\u001b[39m=\u001b[39;49mn_fold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                           current_fold\u001b[39m=\u001b[39;49mfold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                           train_val_size\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m1.0\u001b[39;49m \u001b[39m*\u001b[39;49m pos_train_val_size),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                           test_size\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(\u001b[39m0.0\u001b[39;49m \u001b[39m*\u001b[39;49m X_data\u001b[39m.\u001b[39;49mpos_test_size), \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                           seed\u001b[39m=\u001b[39;49m\u001b[39m6666\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpopularity\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ds_train \u001b[39m=\u001b[39m Dataset()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Dropbox/PyBMF/ex04_asso_netflix.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m ds_train\u001b[39m.\u001b[39mload_data(X\u001b[39m=\u001b[39mX_data\u001b[39m.\u001b[39mtrain_data, U\u001b[39m=\u001b[39mX_data\u001b[39m.\u001b[39mU, V\u001b[39m=\u001b[39mX_data\u001b[39m.\u001b[39mV)\n",
      "File \u001b[1;32md:\\Dropbox\\PyBMF\\datasets\\data.py:168\u001b[0m, in \u001b[0;36mData.cv_negative_sample\u001b[1;34m(self, test_size, n_folds, current_fold, train_val_size, seed, type)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[I]   seed         :\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed)\n\u001b[0;32m    165\u001b[0m train_idx, val_idx, test_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_get_indices(\n\u001b[0;32m    166\u001b[0m     data_idx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_neg_data_idx, partition\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv_neg_partition, current_fold\u001b[39m=\u001b[39mcurrent_fold)\n\u001b[1;32m--> 168\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_neg_data(train_idx, val_idx, test_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mU_neg, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mV_neg)\n",
      "File \u001b[1;32md:\\Dropbox\\PyBMF\\datasets\\data.py:331\u001b[0m, in \u001b[0;36mData.load_neg_data\u001b[1;34m(self, train_idx, val_idx, test_idx, U_neg, V_neg)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_neg_data\u001b[39m(\u001b[39mself\u001b[39m, train_idx, val_idx, test_idx, U_neg, V_neg):\n\u001b[0;32m    329\u001b[0m     \u001b[39m# coo type does not support item assignment, force to use csr\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data\u001b[39m.\u001b[39mmatrix \u001b[39m=\u001b[39m to_sparse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data\u001b[39m.\u001b[39mmatrix, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_data\u001b[39m.\u001b[39mmatrix \u001b[39m=\u001b[39m to_sparse(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_data\u001b[39m.\u001b[39;49mmatrix, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    332\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_data\u001b[39m.\u001b[39mmatrix \u001b[39m=\u001b[39m to_sparse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_data\u001b[39m.\u001b[39mmatrix, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    334\u001b[0m     \u001b[39m# remove zeros in sparse matrices\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dropbox\\PyBMF\\utils\\sparse_utils.py:12\u001b[0m, in \u001b[0;36mto_sparse\u001b[1;34m(X, type)\u001b[0m\n\u001b[0;32m     10\u001b[0m     X \u001b[39m=\u001b[39m coo_matrix(X)\n\u001b[0;32m     11\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 12\u001b[0m     X \u001b[39m=\u001b[39m csr_matrix(X)\n\u001b[0;32m     13\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     14\u001b[0m     X \u001b[39m=\u001b[39m csc_matrix(X)\n",
      "File \u001b[1;32mc:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_compressed.py:84\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munrecognized \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_matrix constructor usage\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(\n\u001b[0;32m     85\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_coo_container(arg1, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m     86\u001b[0m     ))\n\u001b[0;32m     88\u001b[0m \u001b[39m# Read matrix dimensions given, if any\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_compressed.py:33\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     31\u001b[0m         arg1 \u001b[39m=\u001b[39m arg1\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m     32\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         arg1 \u001b[39m=\u001b[39m arg1\u001b[39m.\u001b[39;49masformat(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat)\n\u001b[0;32m     34\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_self(arg1)\n\u001b[0;32m     36\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg1, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_base.py:376\u001b[0m, in \u001b[0;36mspmatrix.asformat\u001b[1;34m(self, format, copy)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[39m# Forward the copy kwarg, if it's accepted.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method(copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    377\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m     \u001b[39mreturn\u001b[39;00m convert_method()\n",
      "File \u001b[1;32mc:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_coo.py:392\u001b[0m, in \u001b[0;36mcoo_matrix.tocsr\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert this matrix to Compressed Sparse Row format\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \n\u001b[0;32m    374\u001b[0m \u001b[39mDuplicate entries will be summed together.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \n\u001b[0;32m    390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnnz \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 392\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_csr_container(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype)\n\u001b[0;32m    393\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m     M,N \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_compressed.py:45\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39m# Select index dtype large enough to pass array and\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39m# scalar parameters to sparsetools\u001b[39;00m\n\u001b[0;32m     44\u001b[0m idx_dtype \u001b[39m=\u001b[39m get_index_dtype(maxval\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(M, N))\n\u001b[1;32m---> 45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m0\u001b[39m, getdtype(dtype, default\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m))\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m0\u001b[39m, idx_dtype)\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindptr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swap((M, N))[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m     48\u001b[0m                        dtype\u001b[39m=\u001b[39midx_dtype)\n",
      "File \u001b[1;32mc:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_sputils.py:126\u001b[0m, in \u001b[0;36mgetdtype\u001b[1;34m(dtype, a, default)\u001b[0m\n\u001b[0;32m    124\u001b[0m     newdtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m    125\u001b[0m     \u001b[39mif\u001b[39;00m newdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m--> 126\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    127\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mobject dtype is not supported by sparse matrices\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m         )\n\u001b[0;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m newdtype\n",
      "\u001b[1;31mValueError\u001b[0m: object dtype is not supported by sparse matrices"
     ]
    }
   ],
   "source": [
    "# k-fold\n",
    "\n",
    "from models import Asso\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "n_fold = 1\n",
    "\n",
    "for i in range(n_fold):\n",
    "    fold = i + 1\n",
    "\n",
    "    X_data.cross_validation(test_size=0, n_folds=5, current_fold=fold, seed=1997)\n",
    "    pos_train_val_size = X_data.pos_train_size + X_data.pos_val_size\n",
    "    X_data.cv_negative_sample(n_folds=n_fold,\n",
    "                              current_fold=fold,\n",
    "                              train_val_size=int(1.0 * pos_train_val_size),\n",
    "                              test_size=int(0.0 * X_data.pos_test_size), \n",
    "                              seed=6666, type='popularity')\n",
    "\n",
    "    ds_train = Dataset()\n",
    "    ds_train.load_data(X=X_data.train_data, U=X_data.U, V=X_data.V)\n",
    "\n",
    "    ds_val = Dataset()\n",
    "    ds_val.load_data(X=X_data.val_data, U=X_data.U, V=X_data.V)\n",
    "\n",
    "    ds_test = Dataset()\n",
    "    ds_test.load_data(X=X_data.test_data, U=X_data.U, V=X_data.V)\n",
    "\n",
    "    ds_train.summarize(title='training set {}'.format(fold), display=True, pixels=2, ordered=True)\n",
    "    ds_val.summarize(title='validation set {}'.format(fold), display=True, pixels=2, ordered=True)\n",
    "    ds_test.summarize(title='test set {}'.format(fold), display=True, pixels=2, ordered=True)\n",
    "\n",
    "\n",
    "    # check tau\n",
    "    tau_list = [0.20, 0.30, 0.40, 0.50, 0.60]\n",
    "    for tau in tau_list:\n",
    "        asso = Asso(k=5, tau=tau, w=[0.5, 0.5])\n",
    "        asso._fit_prepare(train_set=ds_train, display=True)\n",
    "    break\n",
    "\n",
    "\n",
    "    # # grid search\n",
    "    # k = 50\n",
    "    # tau_list = [0.20, 0.30, 0.40, 0.50, 0.60]\n",
    "    # w_list = [[0.7, 0.3], [0.8, 0.2], [0.9, 0.1]]\n",
    "    # for tau in tau_list:\n",
    "    #     for w in w_list:\n",
    "    #         asso = Asso(k=k, tau=tau, w=w)\n",
    "    #         asso._fit_prepare(train_set=ds_train, display=False)\n",
    "    #         asso.fit(train_set=ds_train, display=True)\n",
    "    #         tpr, fpr = asso.eval(test_set=ds_val, triplet=True)\n",
    "\n",
    "    #         str = 'k: {}\\t tau: {}\\t w: {}\\t tpr: {:.2f}\\t fpr: {:.2f}\\n'.format(k, tau, w, tpr, fpr)\n",
    "\n",
    "    #         with open('.\\output\\exp01.txt', \"a\") as f:\n",
    "    #             f.write(str)\n",
    "                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
