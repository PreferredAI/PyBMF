{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from models import Asso\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Boolean matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] m            : 1000\n",
      "[I] n            : 500\n",
      "[I] k            : 5\n",
      "[I] overlap_flag : False\n",
      "[I] size_range   : [0.25 0.75 0.25 1.  ]\n",
      "[I] seed         : 1234\n",
      "[I] noise        : [0.4  0.02]\n",
      "[I] seed         : 1024\n",
      "[I] Using RandomState.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350.694x697.917 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate arbitrary Boolean matrix (X)\n",
    "\n",
    "from generators import DiagBooleanMatrix, ArbiBooleanMatrix\n",
    "\n",
    "n_row=1000\n",
    "n_col=500\n",
    "k=5\n",
    "overlap_flag=True\n",
    "noise=[0.4, 0.02]\n",
    "size_range=[0.25, 0.75, 0.25, 1.0]\n",
    "\n",
    "X = ArbiBooleanMatrix(m=n_row, n=n_col, k=k, overlap_flag=False, size_range=size_range)\n",
    "X.generate(seed=1234) # if no seed assigned, use time instead\n",
    "X.add_noise(noise=noise, seed=1024)\n",
    "X.show_matrix(scaling=0.2, title='arbitrary boolean matrix X')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Prediction task with k-Fold Cross-Validation\n",
    "\n",
    "Assume we have k and tau, now we optimize over w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] CrossValidation, sampling positives\n",
      "[I]   seed         : 1997\n",
      "[I]   n_folds      : 5\n",
      "[I]   partition    : [0, 4501, 9002, 13503, 18003, 22503]\n",
      "[I]   train + val  : 22503\n",
      "[I]   test_size    : 5626\n",
      "[I] CrossValidation, sampling negatives\n",
      "[I]   seed         : 2023\n",
      "[I]   n_folds      : 5\n",
      "[I]   partition    : [0, 4501, 9002, 13503, 18003, 22503]\n",
      "[I]   train + val  : 22503\n",
      "[I]   test_size    : 5626\n"
     ]
    }
   ],
   "source": [
    "from datasets import CrossValidation\n",
    "\n",
    "X_split = CrossValidation(X=X.X, test_size=0.2, n_folds=5, seed=1997)\n",
    "X_split.negative_sample(train_val_size=X_split.pos_train_val_size, \n",
    "                        test_size=X_split.pos_test_size, \n",
    "                        seed=2023, type='popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty table\n",
    "from utils import add_log\n",
    "metrics = ['Recall', 'Precision', 'Error', 'Accuracy', 'F1']\n",
    "columns = ['time', 'k', 'tau', 'p_pos', 'p_neg'] + metrics\n",
    "df_prediction_val = pd.DataFrame(columns=columns)\n",
    "df_prediction_test = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] CrossValidation, current fold : 1\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.6, 0.4]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:24<00:00,  4.88s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 2\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.6, 0.4]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.92s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 3\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.6, 0.4]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:25<00:00,  5.19s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 4\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.6, 0.4]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:24<00:00,  4.96s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 5\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.6, 0.4]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:24<00:00,  4.97s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 1\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.7, 0.3]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.28s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 2\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.7, 0.3]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.21s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 3\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.7, 0.3]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.24s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 4\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.7, 0.3]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.25s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 5\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.7, 0.3]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.20s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 1\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.8, 0.2]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.23s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 2\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.8, 0.2]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.28s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 3\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.8, 0.2]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.38s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 4\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.8, 0.2]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.38s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 5\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.8, 0.2]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:26<00:00,  5.40s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 1\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 1\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.9, 0.1]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:28<00:00,  5.63s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 2\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 2\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.9, 0.1]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:28<00:00,  5.74s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 3\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold size            : (18002, 4501, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 3\n",
      "[I]   current train size   : 18002\n",
      "[I]   current val size     : 4501\n",
      "[I]   fold neg sample size : (18002, 4501, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.9, 0.1]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:27<00:00,  5.48s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 4\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 4\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.9, 0.1]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:29<00:00,  5.90s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n",
      "[I] CrossValidation, current fold : 5\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold size            : (18003, 4500, 5626)\n",
      "[I] CrossValidation, get indices for current fold\n",
      "[I]   current fold         : 5\n",
      "[I]   current train size   : 18003\n",
      "[I]   current val size     : 4500\n",
      "[I]   fold neg sample size : (18003, 4500, 5626)\n",
      "[I] k            : 5\n",
      "[I] tau          : 0.15\n",
      "[I] weights      : [0.9, 0.1]\n",
      "[W] Missing validation data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nieht\\Anaconda3\\envs\\cornac\\lib\\site-packages\\scipy\\sparse\\_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "100%|██████████| 5/5 [00:28<00:00,  5.77s/it]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I] task         : prediction\n"
     ]
    }
   ],
   "source": [
    "# grid search, apply best\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "k = 5\n",
    "tau = 0.15\n",
    "w_list = [[0.6, 0.4], [0.7, 0.3], [0.8, 0.2], [0.9, 0.1]]\n",
    "\n",
    "for w in w_list:\n",
    "\n",
    "    for i in range(n_fold):\n",
    "        # get current fold\n",
    "        current_fold = i + 1\n",
    "        X_data = X_split.get_fold(current_fold=current_fold)\n",
    "        X_train, X_val, X_test = X_split.X_train, X_split.X_val, X_split.X_test\n",
    "\n",
    "        asso = Asso(k=k, tau=tau, w=w)\n",
    "        asso.fit(X_train)\n",
    "\n",
    "        results = asso.eval(X_val, metrics=metrics, task='prediction')\n",
    "        add_log(df_prediction_val, [pd.Timestamp.now(), k, tau, w[0], w[1]] + results)\n",
    "\n",
    "        # just to illustrate the accuracy gap between val and test\n",
    "        # usually test data is not accessible during fitting\n",
    "        results = asso.eval(X_test, metrics=metrics, task='prediction')\n",
    "        add_log(df_prediction_test, [pd.Timestamp.now(), k, tau, w[0], w[1]] + results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>k</th>\n",
       "      <th>tau</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precsion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-08 04:48:31.144887</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.221062</td>\n",
       "      <td>0.866725</td>\n",
       "      <td>0.406465</td>\n",
       "      <td>0.593535</td>\n",
       "      <td>0.352275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-08 04:49:03.955334</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.237947</td>\n",
       "      <td>0.865804</td>\n",
       "      <td>0.399467</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.373301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-08 04:49:38.333342</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.211953</td>\n",
       "      <td>0.884152</td>\n",
       "      <td>0.407909</td>\n",
       "      <td>0.592091</td>\n",
       "      <td>0.341935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-08 04:50:11.260055</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.877157</td>\n",
       "      <td>0.417444</td>\n",
       "      <td>0.582556</td>\n",
       "      <td>0.315041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-08 04:50:44.240694</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.225556</td>\n",
       "      <td>0.868263</td>\n",
       "      <td>0.404333</td>\n",
       "      <td>0.595667</td>\n",
       "      <td>0.358088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-12-08 04:51:18.811742</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.583648</td>\n",
       "      <td>0.865568</td>\n",
       "      <td>0.253499</td>\n",
       "      <td>0.746501</td>\n",
       "      <td>0.697187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-08 04:51:52.936655</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.578094</td>\n",
       "      <td>0.865602</td>\n",
       "      <td>0.255832</td>\n",
       "      <td>0.744168</td>\n",
       "      <td>0.693220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-12-08 04:52:27.272211</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.582315</td>\n",
       "      <td>0.878646</td>\n",
       "      <td>0.249056</td>\n",
       "      <td>0.750944</td>\n",
       "      <td>0.700428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-12-08 04:53:01.604057</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.590444</td>\n",
       "      <td>0.870862</td>\n",
       "      <td>0.248556</td>\n",
       "      <td>0.751444</td>\n",
       "      <td>0.703748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-12-08 04:53:35.708261</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.583111</td>\n",
       "      <td>0.865435</td>\n",
       "      <td>0.253778</td>\n",
       "      <td>0.746222</td>\n",
       "      <td>0.696760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-12-08 04:54:10.189694</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666963</td>\n",
       "      <td>0.864134</td>\n",
       "      <td>0.218951</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.752853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-12-08 04:54:45.238157</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.665408</td>\n",
       "      <td>0.863859</td>\n",
       "      <td>0.219729</td>\n",
       "      <td>0.780271</td>\n",
       "      <td>0.751757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-12-08 04:55:20.330401</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666074</td>\n",
       "      <td>0.878664</td>\n",
       "      <td>0.212953</td>\n",
       "      <td>0.787047</td>\n",
       "      <td>0.757740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-12-08 04:55:55.554640</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.660889</td>\n",
       "      <td>0.869591</td>\n",
       "      <td>0.219111</td>\n",
       "      <td>0.780889</td>\n",
       "      <td>0.751010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-12-08 04:56:30.783639</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.666222</td>\n",
       "      <td>0.862734</td>\n",
       "      <td>0.219889</td>\n",
       "      <td>0.780111</td>\n",
       "      <td>0.751850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-12-08 04:57:06.984084</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.677405</td>\n",
       "      <td>0.786027</td>\n",
       "      <td>0.253499</td>\n",
       "      <td>0.746501</td>\n",
       "      <td>0.727685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-12-08 04:57:43.825475</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.669407</td>\n",
       "      <td>0.774749</td>\n",
       "      <td>0.262608</td>\n",
       "      <td>0.737392</td>\n",
       "      <td>0.718236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-12-08 04:58:19.271318</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.671851</td>\n",
       "      <td>0.858847</td>\n",
       "      <td>0.219285</td>\n",
       "      <td>0.780715</td>\n",
       "      <td>0.753927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-12-08 04:58:56.967068</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.670444</td>\n",
       "      <td>0.761100</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.712902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-12-08 04:59:33.929376</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.671111</td>\n",
       "      <td>0.791197</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.747000</td>\n",
       "      <td>0.726223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  k   tau  p_pos  p_neg    Recall  Precsion  \\\n",
       "0  2023-12-08 04:48:31.144887  5  0.15    0.6    0.4  0.221062  0.866725   \n",
       "1  2023-12-08 04:49:03.955334  5  0.15    0.6    0.4  0.237947  0.865804   \n",
       "2  2023-12-08 04:49:38.333342  5  0.15    0.6    0.4  0.211953  0.884152   \n",
       "3  2023-12-08 04:50:11.260055  5  0.15    0.6    0.4  0.192000  0.877157   \n",
       "4  2023-12-08 04:50:44.240694  5  0.15    0.6    0.4  0.225556  0.868263   \n",
       "5  2023-12-08 04:51:18.811742  5  0.15    0.7    0.3  0.583648  0.865568   \n",
       "6  2023-12-08 04:51:52.936655  5  0.15    0.7    0.3  0.578094  0.865602   \n",
       "7  2023-12-08 04:52:27.272211  5  0.15    0.7    0.3  0.582315  0.878646   \n",
       "8  2023-12-08 04:53:01.604057  5  0.15    0.7    0.3  0.590444  0.870862   \n",
       "9  2023-12-08 04:53:35.708261  5  0.15    0.7    0.3  0.583111  0.865435   \n",
       "10 2023-12-08 04:54:10.189694  5  0.15    0.8    0.2  0.666963  0.864134   \n",
       "11 2023-12-08 04:54:45.238157  5  0.15    0.8    0.2  0.665408  0.863859   \n",
       "12 2023-12-08 04:55:20.330401  5  0.15    0.8    0.2  0.666074  0.878664   \n",
       "13 2023-12-08 04:55:55.554640  5  0.15    0.8    0.2  0.660889  0.869591   \n",
       "14 2023-12-08 04:56:30.783639  5  0.15    0.8    0.2  0.666222  0.862734   \n",
       "15 2023-12-08 04:57:06.984084  5  0.15    0.9    0.1  0.677405  0.786027   \n",
       "16 2023-12-08 04:57:43.825475  5  0.15    0.9    0.1  0.669407  0.774749   \n",
       "17 2023-12-08 04:58:19.271318  5  0.15    0.9    0.1  0.671851  0.858847   \n",
       "18 2023-12-08 04:58:56.967068  5  0.15    0.9    0.1  0.670444  0.761100   \n",
       "19 2023-12-08 04:59:33.929376  5  0.15    0.9    0.1  0.671111  0.791197   \n",
       "\n",
       "       Error  Accuracy        F1  \n",
       "0   0.406465  0.593535  0.352275  \n",
       "1   0.399467  0.600533  0.373301  \n",
       "2   0.407909  0.592091  0.341935  \n",
       "3   0.417444  0.582556  0.315041  \n",
       "4   0.404333  0.595667  0.358088  \n",
       "5   0.253499  0.746501  0.697187  \n",
       "6   0.255832  0.744168  0.693220  \n",
       "7   0.249056  0.750944  0.700428  \n",
       "8   0.248556  0.751444  0.703748  \n",
       "9   0.253778  0.746222  0.696760  \n",
       "10  0.218951  0.781049  0.752853  \n",
       "11  0.219729  0.780271  0.751757  \n",
       "12  0.212953  0.787047  0.757740  \n",
       "13  0.219111  0.780889  0.751010  \n",
       "14  0.219889  0.780111  0.751850  \n",
       "15  0.253499  0.746501  0.727685  \n",
       "16  0.262608  0.737392  0.718236  \n",
       "17  0.219285  0.780715  0.753927  \n",
       "18  0.270000  0.730000  0.712902  \n",
       "19  0.253000  0.747000  0.726223  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nieht\\AppData\\Local\\Temp\\ipykernel_31976\\2615849137.py:5: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df = df.groupby(['p_pos', 'p_neg']).mean().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "      <th>k</th>\n",
       "      <th>tau</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precsion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.217704</td>\n",
       "      <td>0.872420</td>\n",
       "      <td>0.407124</td>\n",
       "      <td>0.592876</td>\n",
       "      <td>0.348128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.583522</td>\n",
       "      <td>0.869223</td>\n",
       "      <td>0.252144</td>\n",
       "      <td>0.747856</td>\n",
       "      <td>0.698268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.665111</td>\n",
       "      <td>0.867796</td>\n",
       "      <td>0.218127</td>\n",
       "      <td>0.781873</td>\n",
       "      <td>0.753042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.672044</td>\n",
       "      <td>0.794384</td>\n",
       "      <td>0.251678</td>\n",
       "      <td>0.748322</td>\n",
       "      <td>0.727795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p_pos  p_neg    k   tau    Recall  Precsion     Error  Accuracy        F1\n",
       "0    0.6    0.4  5.0  0.15  0.217704  0.872420  0.407124  0.592876  0.348128\n",
       "1    0.7    0.3  5.0  0.15  0.583522  0.869223  0.252144  0.747856  0.698268\n",
       "2    0.8    0.2  5.0  0.15  0.665111  0.867796  0.218127  0.781873  0.753042\n",
       "3    0.9    0.1  5.0  0.15  0.672044  0.794384  0.251678  0.748322  0.727795"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# find best params\n",
    "\n",
    "df = df_prediction_val.copy()\n",
    "display(df)\n",
    "df = df.groupby(['p_pos', 'p_neg']).mean().reset_index()\n",
    "display(df)\n",
    "\n",
    "best_idx = df['F1'].idxmax()\n",
    "p_pos = df['p_pos'][best_idx]\n",
    "p_neg = df['p_neg'][best_idx]\n",
    "w = [p_pos, p_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>k</th>\n",
       "      <th>tau</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precsion</th>\n",
       "      <th>Error</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-08 04:48:35.391214</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.224671</td>\n",
       "      <td>0.853477</td>\n",
       "      <td>0.406950</td>\n",
       "      <td>0.593050</td>\n",
       "      <td>0.355706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-08 04:49:08.422085</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.244401</td>\n",
       "      <td>0.871909</td>\n",
       "      <td>0.395752</td>\n",
       "      <td>0.604248</td>\n",
       "      <td>0.381785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-08 04:49:42.597840</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.220761</td>\n",
       "      <td>0.866109</td>\n",
       "      <td>0.406683</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>0.351841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-08 04:50:15.506210</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.194632</td>\n",
       "      <td>0.880225</td>\n",
       "      <td>0.415926</td>\n",
       "      <td>0.584074</td>\n",
       "      <td>0.318777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-08 04:50:48.461144</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.220228</td>\n",
       "      <td>0.864620</td>\n",
       "      <td>0.407128</td>\n",
       "      <td>0.592872</td>\n",
       "      <td>0.351041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-12-08 04:51:23.054288</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.587096</td>\n",
       "      <td>0.866702</td>\n",
       "      <td>0.251600</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>0.700011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-12-08 04:51:57.120709</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.593672</td>\n",
       "      <td>0.866857</td>\n",
       "      <td>0.248756</td>\n",
       "      <td>0.751244</td>\n",
       "      <td>0.704716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-12-08 04:52:31.521918</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.594383</td>\n",
       "      <td>0.872879</td>\n",
       "      <td>0.246090</td>\n",
       "      <td>0.753910</td>\n",
       "      <td>0.707201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-12-08 04:53:05.784090</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.600782</td>\n",
       "      <td>0.869118</td>\n",
       "      <td>0.244845</td>\n",
       "      <td>0.755155</td>\n",
       "      <td>0.710457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-12-08 04:53:39.948135</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.588518</td>\n",
       "      <td>0.866981</td>\n",
       "      <td>0.250889</td>\n",
       "      <td>0.749111</td>\n",
       "      <td>0.701112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-12-08 04:54:14.858866</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.667970</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>0.217206</td>\n",
       "      <td>0.782794</td>\n",
       "      <td>0.754618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-12-08 04:54:49.441591</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>0.216584</td>\n",
       "      <td>0.783416</td>\n",
       "      <td>0.755738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-12-08 04:55:24.655962</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.667792</td>\n",
       "      <td>0.865469</td>\n",
       "      <td>0.218006</td>\n",
       "      <td>0.781994</td>\n",
       "      <td>0.753888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-12-08 04:55:59.903249</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.866559</td>\n",
       "      <td>0.216317</td>\n",
       "      <td>0.783683</td>\n",
       "      <td>0.756112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-12-08 04:56:34.966696</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.667081</td>\n",
       "      <td>0.866144</td>\n",
       "      <td>0.218006</td>\n",
       "      <td>0.781994</td>\n",
       "      <td>0.753690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-12-08 04:57:11.244956</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.678457</td>\n",
       "      <td>0.789779</td>\n",
       "      <td>0.251066</td>\n",
       "      <td>0.748934</td>\n",
       "      <td>0.729898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-12-08 04:57:47.983208</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.675791</td>\n",
       "      <td>0.782949</td>\n",
       "      <td>0.255777</td>\n",
       "      <td>0.744223</td>\n",
       "      <td>0.725434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-12-08 04:58:23.530728</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.673658</td>\n",
       "      <td>0.848634</td>\n",
       "      <td>0.223249</td>\n",
       "      <td>0.776751</td>\n",
       "      <td>0.751090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-12-08 04:59:01.186913</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>0.764882</td>\n",
       "      <td>0.264309</td>\n",
       "      <td>0.735691</td>\n",
       "      <td>0.720278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-12-08 04:59:38.157748</td>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.675969</td>\n",
       "      <td>0.799622</td>\n",
       "      <td>0.246712</td>\n",
       "      <td>0.753288</td>\n",
       "      <td>0.732614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         time  k   tau  p_pos  p_neg    Recall  Precsion  \\\n",
       "0  2023-12-08 04:48:35.391214  5  0.15    0.6    0.4  0.224671  0.853477   \n",
       "1  2023-12-08 04:49:08.422085  5  0.15    0.6    0.4  0.244401  0.871909   \n",
       "2  2023-12-08 04:49:42.597840  5  0.15    0.6    0.4  0.220761  0.866109   \n",
       "3  2023-12-08 04:50:15.506210  5  0.15    0.6    0.4  0.194632  0.880225   \n",
       "4  2023-12-08 04:50:48.461144  5  0.15    0.6    0.4  0.220228  0.864620   \n",
       "5  2023-12-08 04:51:23.054288  5  0.15    0.7    0.3  0.587096  0.866702   \n",
       "6  2023-12-08 04:51:57.120709  5  0.15    0.7    0.3  0.593672  0.866857   \n",
       "7  2023-12-08 04:52:31.521918  5  0.15    0.7    0.3  0.594383  0.872879   \n",
       "8  2023-12-08 04:53:05.784090  5  0.15    0.7    0.3  0.600782  0.869118   \n",
       "9  2023-12-08 04:53:39.948135  5  0.15    0.7    0.3  0.588518  0.866981   \n",
       "10 2023-12-08 04:54:14.858866  5  0.15    0.8    0.2  0.667970  0.867097   \n",
       "11 2023-12-08 04:54:49.441591  5  0.15    0.8    0.2  0.670103  0.866467   \n",
       "12 2023-12-08 04:55:24.655962  5  0.15    0.8    0.2  0.667792  0.865469   \n",
       "13 2023-12-08 04:55:59.903249  5  0.15    0.8    0.2  0.670636  0.866559   \n",
       "14 2023-12-08 04:56:34.966696  5  0.15    0.8    0.2  0.667081  0.866144   \n",
       "15 2023-12-08 04:57:11.244956  5  0.15    0.9    0.1  0.678457  0.789779   \n",
       "16 2023-12-08 04:57:47.983208  5  0.15    0.9    0.1  0.675791  0.782949   \n",
       "17 2023-12-08 04:58:23.530728  5  0.15    0.9    0.1  0.673658  0.848634   \n",
       "18 2023-12-08 04:59:01.186913  5  0.15    0.9    0.1  0.680590  0.764882   \n",
       "19 2023-12-08 04:59:38.157748  5  0.15    0.9    0.1  0.675969  0.799622   \n",
       "\n",
       "       Error  Accuracy        F1  \n",
       "0   0.406950  0.593050  0.355706  \n",
       "1   0.395752  0.604248  0.381785  \n",
       "2   0.406683  0.593317  0.351841  \n",
       "3   0.415926  0.584074  0.318777  \n",
       "4   0.407128  0.592872  0.351041  \n",
       "5   0.251600  0.748400  0.700011  \n",
       "6   0.248756  0.751244  0.704716  \n",
       "7   0.246090  0.753910  0.707201  \n",
       "8   0.244845  0.755155  0.710457  \n",
       "9   0.250889  0.749111  0.701112  \n",
       "10  0.217206  0.782794  0.754618  \n",
       "11  0.216584  0.783416  0.755738  \n",
       "12  0.218006  0.781994  0.753888  \n",
       "13  0.216317  0.783683  0.756112  \n",
       "14  0.218006  0.781994  0.753690  \n",
       "15  0.251066  0.748934  0.729898  \n",
       "16  0.255777  0.744223  0.725434  \n",
       "17  0.223249  0.776751  0.751090  \n",
       "18  0.264309  0.735691  0.720278  \n",
       "19  0.246712  0.753288  0.732614  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if the best w on X_val is best on X_test\n",
    "display(df_prediction_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
